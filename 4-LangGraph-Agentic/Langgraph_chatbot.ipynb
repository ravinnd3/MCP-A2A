{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0207adf6",
   "metadata": {},
   "source": [
    "# LangGraph Chatbot Hands On without LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb5021a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravianand/Documents/VSCODE_PY/MCP_A2A/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "import operator\n",
    "import gradio as gr\n",
    "import random\n",
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9b2abf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the State properly using TypedDict\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff95545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nodes that return proper state updates\n",
    "def greeter(state: State):\n",
    "    \"\"\"Welcome message - only sent once per conversation\"\"\"\n",
    "    if not any(isinstance(msg, AIMessage) for msg in state[\"messages\"]):\n",
    "        return {\"messages\": [AIMessage(content=\"ðŸ‘‹ Hello! I'm your chatbot.\")]}\n",
    "    return {\"messages\": []}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c1c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo_user(state: State):\n",
    "    \"\"\"Echo user input\"\"\"\n",
    "    # Get the last user message\n",
    "    user_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    if user_messages:\n",
    "        last_user_msg = user_messages[-1]\n",
    "        return {\"messages\": [AIMessage(content=f\"ðŸ—£ You said: {last_user_msg.content}\")]}\n",
    "    return {\"messages\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d4f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fact(state: State):\n",
    "    \"\"\"Provide a random fact\"\"\"\n",
    "    facts = [\n",
    "        \"Bananas are berries, but strawberries aren't.\",\n",
    "        \"Octopuses have three hearts.\",\n",
    "        \"Penguins propose with pebbles.\"\n",
    "    ]\n",
    "    return {\"messages\": [AIMessage(content=f\"ðŸ¤¯ Fun Fact: {random.choice(facts)}\")]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679c8db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def farewell(state: State):\n",
    "    \"\"\"Say goodbye\"\"\"\n",
    "    return {\"messages\": [AIMessage(content=\"ðŸ‘‹ Goodbye! Come chat again.\")]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31763ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router function for conditional edges\n",
    "def router(state: State):\n",
    "    \"\"\"Determine which node to execute based on user input\"\"\"\n",
    "\n",
    "    # Get the last user message\n",
    "    user_messages = [msg for msg in state[\"messages\"] if isinstance(msg, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        return \"greeter\"\n",
    "\n",
    "    last_user_msg = user_messages[-1]\n",
    "    user_input = last_user_msg.content.lower()\n",
    "\n",
    "    if \"fact\" in user_input:\n",
    "        return \"fact\"\n",
    "    elif any(word in user_input for word in [\"bye\", \"goodbye\", \"exit\", \"quit\"]):\n",
    "        return \"farewell\"\n",
    "    else:\n",
    "        return \"echo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd61be98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x11941f890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Graph\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "builder.add_node(\"greeter\", greeter)\n",
    "builder.add_node(\"echo\", echo_user)\n",
    "builder.add_node(\"fact\", random_fact)\n",
    "builder.add_node(\"farewell\", farewell)\n",
    "\n",
    "# Set up conditional routing\n",
    "builder.add_conditional_edges(\n",
    "    START, \n",
    "    router, \n",
    "    [\"greeter\", \"echo\", \"fact\", \"farewell\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "723bdf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edges from nodes to END\n",
    "builder.add_edge(\"greeter\", END)\n",
    "builder.add_edge(\"echo\", END)\n",
    "builder.add_edge(\"fact\", END)\n",
    "builder.add_edge(\"farewell\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fff4453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to print state in a readable format\n",
    "def print_state(state, title=\"State\"):\n",
    "    \"\"\"Print the state in a readable format\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    if \"messages\" in state:\n",
    "        print(\"Messages:\")\n",
    "        for i, msg in enumerate(state[\"messages\"]):\n",
    "            msg_type = \"Human\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "            print(f\"  {i}: [{msg_type}] {msg.content}\")\n",
    "    else:\n",
    "        print(\"No messages in state\")\n",
    "    print(\"=================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47f2db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio Chat Interface\n",
    "def chat_fn(message, chat_history):\n",
    "    \"\"\"Handle chat interactions\"\"\"\n",
    "    # Convert chat history to messages\n",
    "    messages = []\n",
    "    for user_msg, bot_msg in chat_history:\n",
    "        messages.append(HumanMessage(content=user_msg))\n",
    "        messages.append(AIMessage(content=bot_msg))\n",
    "\n",
    "    # Add the current user message\n",
    "    messages.append(HumanMessage(content=message))\n",
    "\n",
    "    # Create initial state\n",
    "    initial_state = {\"messages\": messages}\n",
    "\n",
    "    # Print initial state\n",
    "    print_state(initial_state, \"Initial State\")\n",
    "\n",
    "    try:\n",
    "        # Execute the graph\n",
    "        result = graph.invoke(initial_state)\n",
    "\n",
    "        # Print final state\n",
    "        print_state(result, \"Final State\")\n",
    "\n",
    "        # Extract the new AI responses (only the ones added in this invocation)\n",
    "        new_ai_messages = [\n",
    "            msg for msg in result[\"messages\"] \n",
    "            if isinstance(msg, AIMessage) and msg not in messages\n",
    "        ]\n",
    "\n",
    "        # Get the latest AI response\n",
    "        latest_response = new_ai_messages[-1].content if new_ai_messages else \"I didn't understand that.\"\n",
    "\n",
    "        # Append to chat history\n",
    "        chat_history.append((message, latest_response))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        chat_history.append((message, \"Sorry, I encountered an error. Please try again.\"))\n",
    "        return \"\", chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "763fcfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸ¤– LangGraph Chatbot Demo\")\n",
    "\n",
    "    chatbot = gr.Chatbot(height=200, label=\"Conversation\")\n",
    "    msg = gr.Textbox(label=\"Your Message\", placeholder=\"Type your message here...\")\n",
    "    clear = gr.Button(\"Clear Chat\")\n",
    "\n",
    "    msg.submit(chat_fn, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5f9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCP_A2A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
